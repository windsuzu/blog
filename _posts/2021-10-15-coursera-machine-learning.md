---
layout: post
title: ğŸ“Œ æ©Ÿå™¨å­¸ç¿’çš„å­¸è¡“ç†è«–ç›®éŒ„ - Machine Learning Theory Catalog
description: 
categories: [Machine Learning, Catalog]
sticky_rank: 1
---

# Introduction

å³æ©é”æ•™æˆçš„æ©Ÿå™¨å­¸ç¿’ {% fn 1 %} æ˜¯æˆ‘æœ€æ¨è–¦çš„åŸºç¤èª²ç¨‹ä¹‹ä¸€ï¼Œä»–ç”¨æ·ºé¡¯æ˜“æ‡‚çš„æ•¸å­¸å°±èƒ½ä»‹ç´¹æ‰€æœ‰æ©Ÿå™¨å­¸ç¿’ç†è«–çš„åŸºç¤ã€‚æˆ‘åœ¨å¸æ”¶å®Œä»–çš„æ•™å­¸å¾Œï¼Œä¹Ÿå¯«äº†ä¸€äº›æ•™å­¸ç­†è¨˜ï¼Œä¸¦ä¸”å°‡æ‰€æœ‰ç­†è¨˜çµ±æ•´åœ¨é€™è£¡ï¼Œæ–¹ä¾¿å¤§å®¶èƒ½å¤ ä¸€èµ·å­¸ç¿’ã€‚

{% include alert.html text="é€™æ˜¯æ–°çš„éƒ¨è½æ ¼ï¼Œç›®å‰é‚„åœ¨æ¬é‹ç­†è¨˜ä¸­"%}

# Catalog

- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - ä»€éº¼æ˜¯æ¨¡å‹ (Model)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - ä»£åƒ¹å‡½æ•¸ (Cost Function) / æå¤±å‡½æ•¸ (Loss Function)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - æ¢¯åº¦ä¸‹é™ (Gradient Descent)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - ç·šæ€§å›æ­¸ (Linear Regression)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - ç·šæ€§åˆ†é¡ (Linear Classification)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - é‚è¼¯æ–¯è¿´æ­¸ (Logistic Regression)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - éåº¦æ“¬åˆ (Overfitting)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - æ€éº¼è§£æ±ºéåº¦æ“¬åˆ (How to Solve Overfitting)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - åå·®é‚„æ˜¯è®Šç•° (Bias or Variance)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - è§£æ±ºåå·®è·Ÿè®Šç•° (Solving Bias/Variance)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - ä»€éº¼æ˜¯ç¥ç¶“ç¶²è·¯ (Neural Network)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - ç¥ç¶“ç¶²è·¯è¦æ€éº¼è¨“ç·´ (Neural Network Training)]()
- [æ©Ÿå™¨å­¸ç¿’åŸºç¤ç†è«– - ä»€éº¼æ˜¯æ”¯æ´å‘é‡æ©Ÿ (SVM, Support Vector Machine)]()

# Credit

- Teached by [Andrew Ng](https://www.coursera.org/instructor/andrewng), CEO/Founder Landing AI; Co-founder, Coursera; Adjunct Professor, Stanford University; formerly Chief Scientist,Baidu and founding lead of Google Brain
- Created by [Stanford University](https://www.coursera.org/learn/machine-learning)


{{ "https://zh-tw.coursera.org/learn/machine-learning" | fndetail: 1 }}
