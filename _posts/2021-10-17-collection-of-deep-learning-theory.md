---
layout: post
title: ğŸ“Œ æ·±åº¦å­¸ç¿’çš„ç†è«–ç›®éŒ„ - Collection of Deep Learning Theory
description: 
categories: [Deep Learning, Recurrent Neural Network, RNN, Convolutional Neural Network, CNN, Collection]
sticky_rank: 2
---

# Prerequisite

å»ºè­°çœ‹å®Œ [æ©Ÿå™¨å­¸ç¿’çš„ç†è«–]({% post_url 2021-10-15-collection-of-machine-learning-theory %}) ä¸¦å­¸æœƒæ©Ÿå™¨å­¸ç¿’çš„åŸºç¤æ¦‚å¿µå¾Œï¼Œå†ä¾†ç ”ç©¶æ·±åº¦å­¸ç¿’ã€‚

# Introduction

æ·±åº¦å­¸ç¿’æ˜¯ç”±æ©Ÿå™¨å­¸ç¿’åˆ†æ”¯å‡ºä¾†çš„ä¸€å€‹å¤§é ˜åŸŸï¼Œå…¶æ¦‚å¿µæ˜¯æ‡‰ç”¨ç¥ç¶“ç¶²è·¯ç‚ºåŸºç¤ï¼Œä¸¦ä»¥ç¾ä»Šç¡¬é«” (ç‰¹åˆ¥æ˜¯ GPU) æ•ˆèƒ½ç‚ºè¼”åŠ©ï¼Œå°‡ç¥ç¶“ç¶²è·¯å»ºç«‹çš„è¶Šä¾†è¶Šå¤§ (**æ·±åº¦**å…©å­—çš„ç”±ä¾†)ã€‚ç¶²è·¯å…§çš„æ‰€æœ‰ç¥ç¶“å…ƒ (neuron) å¯ä»¥è‡ªå‹•å­¸ç¿’åˆ°å•é¡Œæ‰€éœ€çš„åƒæ•¸ï¼Œä¸¦ä»¥æ­¤ä¾†é æ¸¬ã€è§£æ±ºæœªçŸ¥çš„å•é¡Œã€‚

å³æ©é”æ•™æˆçš„æ·±åº¦å­¸ç¿’ {% fn 1 %} æ˜¯æˆ‘æœ€æ¨è–¦çš„æ·±åº¦å­¸ç¿’åŸºç¤èª²ç¨‹ä¹‹ä¸€ï¼Œé€™è£¡ä¸€æ¨£æ˜¯åœ¨å¸æ”¶å®Œæ•™å­¸å¾Œï¼Œæ‰€å¯«çš„ä¸€äº›æ•™å­¸ç­†è¨˜ï¼›æˆ‘å°‡æ‰€æœ‰ç­†è¨˜çµ±æ•´åœ¨é€™è£¡ï¼Œæ–¹ä¾¿å¤§å®¶èƒ½å¤ ä¸€èµ·å­¸ç¿’ã€‚

{% include alert.html text="é€™æ˜¯æ–°çš„éƒ¨è½æ ¼ï¼Œç›®å‰é‚„åœ¨æ¬é‹ç­†è¨˜ä¸­ï¼ŒèˆŠç­†è¨˜åœ¨: https://sejkai.gitbook.io/academic/deep-learning"%}

# Catalog

## Deep Neural Network (DNN)

- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - ä»€éº¼æ˜¯ç¥ç¶“ç¶²è·¯ (Neural Network)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - æ€éº¼è¨“ç·´ç¥ç¶“ç¶²è·¯ - åå‘å‚³æ’­ç®—æ³• (Backpropagation)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - æ€éº¼è¨“ç·´ç¥ç¶“ç¶²è·¯ - æ¿€å‹µå‡½æ•¸ (Activation Function)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - æ·ºå±¤çš„ç¥ç¶“ç¶²è·¯ (SNN, Shallow Neural Network)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - æ·±å±¤çš„ç¥ç¶“ç¶²è·¯ (DNN, Deep Neural Network)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - å°ç¥ç¶“ç¶²è·¯æ­£å‰‡åŒ– (Regularization)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - Dropout æ­£å‰‡åŒ–]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - å„ªåŒ–ç¥ç¶“ç¶²è·¯ (Optimization)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - Momentum, RMSprop, Adam å„ªåŒ–]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - è¶…åƒæ•¸èª¿æ•´ (Hyperparameter Tuning)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - æ‰¹é‡æ­¸ä¸€åŒ– (BN, Batch Normalization)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - Softmax å‡½å¼ (Softmax Regression)]()

## Convolutional Neural Network (CNN)

- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - è¨ˆç®—æ©Ÿè¦–è¦ºèˆ‡å·ç©é‹ç®— (Computer Vision and Convolutional Operation)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - å·ç©ç¥ç¶“ç¶²è·¯ (CNN, Convolutional Neural Network)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - ç¶“å…¸çš„å·ç©ç¥ç¶“ç¶²è·¯ (LeNet-5, AlexNet, VGG)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - æ®˜å·®ç¶²è·¯ (ResNets, Residual Networks)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - Inception ç¶²è·¯]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - ç‰©ä»¶åµæ¸¬ (Object Detection)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - YOLO, You Only Look Once]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - R-CNN]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - äººè‡‰è­˜åˆ¥ (Face Recognition)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - é¢¨æ ¼è½‰æ› (Neural Style Transfer)]()

## Recurrent Neural Network (RNN)

- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - å¾ªç’°ç¥ç¶“ç¶²è·¯ (RNN, Recurrent Neural Network)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - èªè¨€æ¨¡å‹ (Language Model)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - GRU å’Œ LSTM (Gated Recurrent Unit & Long Short Term Memory)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - é›™å‘ã€æ·±åº¦å¾ªç’°ç¥ç¶“ç¶²è·¯ (Bidirectional RNN & Deep RNN)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - è©åµŒå…¥ (Word Embedding)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - Word2Vec è©åµŒå…¥]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - æƒ…æ„Ÿåˆ†é¡ (Sentiment Classification)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - åºåˆ—æ¨¡å‹ (Seq2Seq, Sequence-to-Sequence Model)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - å…‰æŸæœå°‹ (Beam Search)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - BLEU (Bilingual Evaluation Understudy)]()
- [æ·±åº¦å­¸ç¿’åŸºç¤ç†è«– - æ³¨æ„åŠ›æ¨¡å‹ (Attention Model)]()

# Credit

- Teached by [Andrew Ng](https://www.coursera.org/instructor/andrewng), CEO/Founder Landing AI; Co-founder, Coursera; Adjunct Professor, Stanford University; formerly Chief Scientist,Baidu and founding lead of Google Brain
- Created by [Stanford University](https://www.coursera.org/learn/machine-learning)


{{ "https://zh-tw.coursera.org/specializations/deep-learning" | fndetail: 1 }}
